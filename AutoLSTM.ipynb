{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in c:\\users\\himesh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.4.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in c:\\users\\himesh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pydot) (3.0.9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.0.1\n",
      "[notice] To update, run: C:\\Users\\Himesh\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from matplotlib import pyplot\n",
    "from math import ceil\n",
    "from random import shuffle\n",
    "from itertools import chain\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, TimeDistributed, Conv1D, MaxPooling1D, UpSampling1D\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.optimizers as opt\n",
    "import pandas as pd\n",
    "from transformers import RobertaTokenizer\n",
    "import os\n",
    "import transformers\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X, y = make_classification(n_samples=1000, n_features=100, n_informative=10, n_redundant=90, random_state=1)\n",
    "# print(type(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basePath = r'/home/himesh/TagCoder/pythonNotebook'\n",
    "basePath = r'C:\\Users\\Himesh\\Documents\\thesis\\pythonNotebook'\n",
    "positivePathSuffix = '/Positive'\n",
    "negativePathSuffix = '/Negative'\n",
    "tokenizerInPath = basePath + '/tokenizerIn'\n",
    "tokenizerOutPath = basePath + '/tokenizerOut'\n",
    "train_ratio = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90329c754c1a47e59ce2c3b911524275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/703k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Himesh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\huggingface_hub\\file_download.py:129: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Himesh\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22f083bf7c7d429982c8c41c0ff1342e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/294k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fe5367cd8c141d69a95c334e1c0802e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)in/added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b92072adbde472398e7780853d94063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/12.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0f4c5fe66904c00890f7d74e0761ba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/1.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#tokenizer = transformers.AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "#tokenizer = RobertaTokenizer.from_pretrained('Salesforce/codet5-base')\n",
    "tokenizer = RobertaTokenizer.from_pretrained('Salesforce/codet5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_max(arr, dim=\"width\", z=2):\n",
    "    mn = np.mean(arr, axis=0)\n",
    "    sd = np.std(arr, axis=0)\n",
    "    final_list = [x for x in arr if (x <= mn + z * sd)]  # upper outliers removed\n",
    "    rmn2 = len(arr) - len(final_list)\n",
    "    print('{} array size '.format(dim) + str(len(arr)))\n",
    "    print('min {} '.format(dim) + str(min(arr)))\n",
    "    print('max {} '.format(dim) + str(max(arr)))\n",
    "    print('mean {} '.format(dim) + str(np.nanmean(arr)))\n",
    "    print('standard deviation ' + str(np.std(arr)))\n",
    "    print('median {} '.format(dim) + str(np.nanmedian(arr)))\n",
    "    print('number of upper outliers removed ' + str(rmn2))\n",
    "    print('max {} excluding upper outliers '.format(dim) + str(max(final_list)))\n",
    "    return max(final_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_outlier_threshold(path, z, is_c2v):\n",
    "    print('Getting outlier threshold via inner method. The path passed is '+path)\n",
    "    lengths = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for f in files:\n",
    "            if f.startswith(\".\"):\n",
    "                continue\n",
    "            filepath = os.path.join(root, f)\n",
    "            with open(filepath, \"r\", errors='ignore') as file:\n",
    "                #print('Working with file'+ filepath)\n",
    "                for line in file:\n",
    "                    input_str = line.replace(\"\\t\", \" \")\n",
    "                    if is_c2v:\n",
    "                        np_arr = np.fromstring(input_str, dtype=np.float, sep=\" \")\n",
    "                    else:\n",
    "                        np_arr = np.fromstring(input_str, dtype=np.int32, sep=\" \")\n",
    "                    cur_width = len(np_arr)\n",
    "                    #print('cur_width: '+str(cur_width))\n",
    "                    lengths.append(cur_width)\n",
    "    \n",
    "    #print(' '.join(map(str, lengths)))\n",
    "    #print(compute_max(lengths,z=z))\n",
    "    return compute_max(lengths, z=z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting outlier threshold via inner method. The path passed is C:\\Users\\Himesh\\Documents\\thesis\\pythonNotebook/tokenizerOut\\ComplexMethod\\Positive\n",
      "width array size 944\n",
      "min width 512\n",
      "max width 2190\n",
      "mean width 602.8792372881356\n",
      "standard deviation 201.7674766994313\n",
      "median width 512.0\n",
      "number of upper outliers removed 98\n",
      "max width excluding upper outliers 804\n",
      "Getting outlier threshold via inner method. The path passed is C:\\Users\\Himesh\\Documents\\thesis\\pythonNotebook/tokenizerOut\\ComplexMethod\\Negative\n",
      "width array size 1708\n",
      "min width 512\n",
      "max width 8045\n",
      "mean width 618.1996487119438\n",
      "standard deviation 365.292697212631\n",
      "median width 512.0\n",
      "number of upper outliers removed 107\n",
      "max width excluding upper outliers 974\n",
      "974\n"
     ]
    }
   ],
   "source": [
    "len1 = _get_outlier_threshold((os.path.join(tokenizerOutPath,'ComplexMethod','Positive')),z=1,is_c2v = False)\n",
    "len2 = _get_outlier_threshold((os.path.join(tokenizerOutPath,'ComplexMethod','Negative')),z=1,is_c2v = False)\n",
    "\n",
    "if len1 > len2:\n",
    "    maxLength = len1 \n",
    "else:\n",
    "    maxLength = len2\n",
    "\n",
    "print(maxLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Himesh\\Documents\\thesis\\pythonNotebook/tokenizerIn\n",
      "C:\\Users\\Himesh\\Documents\\thesis\\pythonNotebook/tokenizerIn\\ComplexMethod\\Negative\\\n"
     ]
    }
   ],
   "source": [
    "smellList = ['ComplexMethod']\n",
    "final_text = \"\"\n",
    "\n",
    "print(tokenizerInPath)\n",
    "for smell in smellList:\n",
    "    smellPath = os.path.join(tokenizerInPath, smell,'Positive',\"\")\n",
    "    #print(smellPath)\n",
    "    \n",
    "    for file in os.listdir(smellPath):\n",
    "        #print(os.path.basename(file))\n",
    "        with open(os.path.join(smellPath, file),\"r\",encoding='utf-8') as read_file:\n",
    "            try:\n",
    "                text = read_file.read()\n",
    "                tokenized_text = tokenizer.tokenize(text)\n",
    "                input_ids = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "                #print(len(input_ids))\n",
    "                # if len(input_ids) > maxLength:\n",
    "                #     maxLength = len(input_ids)\n",
    "                # modint = (len(input_ids)) % 512\n",
    "                # #print(modint)\n",
    "                # length = len(input_ids) - modint\n",
    "            \n",
    "                # input_ids = input_ids[0:length]\n",
    "                final_text += ' '.join(map(str, input_ids))+'\\n'\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "    #Path(os.path.join(tokenizerOutPath,smell,positivePathSuffix, 'tokenizer.tok')).touch(exist_ok=True)        \n",
    "    with open(os.path.abspath(os.path.join(tokenizerOutPath,smell,'Positive', 'tokenizer.tok')),'w',errors='ignore') as out_file:\n",
    "        #out_file.touch(exist_ok=True)\n",
    "        #print(final_text)\n",
    "        out_file.write(final_text)\n",
    "    \n",
    "smellPath = os.path.join(tokenizerInPath, smell,'Negative',\"\")\n",
    "print(smellPath)\n",
    "\n",
    "for file in os.listdir(smellPath):\n",
    "    #print(os.path.basename(file))\n",
    "    with open(os.path.join(smellPath, file),\"r\",encoding='utf-8') as read_file:\n",
    "        try:\n",
    "            text = read_file.read()\n",
    "#            tokenized_text = tokenizer.tokenize(text,padding = \"max_length\")\n",
    "            tokenized_text = tokenizer.tokenize(text)\n",
    " \n",
    "            input_ids = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "            #print(len(input_ids))\n",
    "            # if len(input_ids) > maxLength:\n",
    "            #     maxLength = len(input_ids)\n",
    "            \n",
    "            # modint = (len(input_ids)) % 512\n",
    "            # #print(modint)\n",
    "            # length = len(input_ids) - modint\n",
    "           \n",
    "            # input_ids = input_ids[0:length]\n",
    "           \n",
    "            final_text += ' '.join(map(str, input_ids))+'\\n'\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "            pass\n",
    "#Path(os.path.join(tokenizerOutPath,smell,positivePathSuffix, 'tokenizer.tok')).touch(exist_ok=True)        \n",
    "with open(os.path.abspath(os.path.join(tokenizerOutPath,smell,'Negative', 'tokenizer.tok')),'w',errors='ignore') as out_file:\n",
    "    #out_file.touch(exist_ok=True)\n",
    "    #print(final_text)\n",
    "    out_file.write(final_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "974\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "num_lines_pos = sum(1 for line in open(os.path.join(tokenizerOutPath,smell,'Positive', 'tokenizer.tok'),\"r\"))\n",
    "with open(os.path.join(tokenizerOutPath,smell,'Positive', 'tokenizer.tok'),\"r\") as read_file:\n",
    "    #text = read_file.read()\n",
    "  \n",
    "    #text = text.replace('\\n', ' ')\n",
    "    #text = text.replace('\\r', ' ')\n",
    "    #print(text)\n",
    "    #posInput = np.fromstring(text, sep=\" \").tolist()\n",
    "    #print(len(posInput))\n",
    "    for line in read_file:\n",
    "        if line == '\\n':\n",
    "            continue \n",
    "        arr = np.fromstring(line, dtype=np.int32, sep=\" \",count=maxLength)\n",
    "        arr_size = len(arr)\n",
    "        if arr_size <= maxLength:\n",
    "                    arr[arr_size:maxLength] = 0\n",
    "        X.append(arr)\n",
    "        Y = Y +[1]\n",
    "\n",
    "with open(os.path.join(tokenizerOutPath,smell,'Negative', 'tokenizer.tok'),\"r\") as read_file:\n",
    "    # text = read_file.read()\n",
    "  \n",
    "    # text = text.replace('\\n', ' ')\n",
    "    # text = text.replace('\\r', ' ')\n",
    "    # #print(text)\n",
    "    # negInput = np.fromstring(text, dtype=np.int32, sep=\" \").tolist()\n",
    "\n",
    "    for line in read_file:\n",
    "        if line == '\\n':\n",
    "            continue\n",
    "        arr = np.fromstring(line, dtype=np.int32, sep=\" \",count=maxLength)\n",
    "        arr_size = len(arr)\n",
    "        if arr_size <= maxLength:\n",
    "                    arr[arr_size:maxLength] = 0\n",
    "        X.append(arr)\n",
    "        Y = Y +[0]\n",
    "print((maxLength))\n",
    "\n",
    "X = np.asarray(X)\n",
    "\n",
    "print(type(X))\n",
    "n_inputs = X.shape[1]\n",
    "X,Y = shuffle(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size= 1 - train_ratio, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arr shape\n",
      "(1856, 974, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0: 512, 1: 284})"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.reshape(-1,maxLength,1)\n",
    "X_test = X_test.reshape(-1,maxLength,1)\n",
    "#shuffle(X_train,y_train)\n",
    "print('arr shape')\n",
    "print(X_train.shape)\n",
    "collections.Counter(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_28 (InputLayer)       [(None, 974, 1)]          0         \n",
      "                                                                 \n",
      " lstm_51 (LSTM)              (None, 974, 8)            320       \n",
      "                                                                 \n",
      " lstm_52 (LSTM)              (None, 974, 8)            544       \n",
      "                                                                 \n",
      " time_distributed_9 (TimeDis  (None, 974, 1)           9         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 873\n",
      "Trainable params: 873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "47/47 [==============================] - 76s 1s/step - loss: 9944030406246400.0000 - mean_squared_error: 9944029332504576.0000 - val_loss: 1090896728686592.0000 - val_mean_squared_error: 1090896862904320.0000\n",
      "Epoch 2/20\n",
      "47/47 [==============================] - 75s 2s/step - loss: 9944030406246400.0000 - mean_squared_error: 9944029332504576.0000 - val_loss: 1090896728686592.0000 - val_mean_squared_error: 1090896862904320.0000\n",
      "Epoch 3/20\n",
      "47/47 [==============================] - 80s 2s/step - loss: 9944029332504576.0000 - mean_squared_error: 9944029332504576.0000 - val_loss: 1090896728686592.0000 - val_mean_squared_error: 1090896862904320.0000\n",
      "Epoch 4/20\n",
      "47/47 [==============================] - 76s 2s/step - loss: 9944029332504576.0000 - mean_squared_error: 9944030406246400.0000 - val_loss: 1090896728686592.0000 - val_mean_squared_error: 1090896862904320.0000\n",
      "Epoch 5/20\n",
      "47/47 [==============================] - 62s 1s/step - loss: 9944027185020928.0000 - mean_squared_error: 9944028258762752.0000 - val_loss: 1090896728686592.0000 - val_mean_squared_error: 1090896862904320.0000\n",
      "Epoch 6/20\n",
      "47/47 [==============================] - 62s 1s/step - loss: 9944028258762752.0000 - mean_squared_error: 9944027185020928.0000 - val_loss: 1090896728686592.0000 - val_mean_squared_error: 1090896862904320.0000\n",
      "Epoch 7/20\n",
      "47/47 [==============================] - 63s 1s/step - loss: 9944029332504576.0000 - mean_squared_error: 9944029332504576.0000 - val_loss: 1090896728686592.0000 - val_mean_squared_error: 1090896862904320.0000\n",
      "Epoch 8/20\n",
      "47/47 [==============================] - 61s 1s/step - loss: 9944030406246400.0000 - mean_squared_error: 9944029332504576.0000 - val_loss: 1090896728686592.0000 - val_mean_squared_error: 1090896862904320.0000\n",
      "Epoch 9/20\n",
      "47/47 [==============================] - 66s 1s/step - loss: 9944029332504576.0000 - mean_squared_error: 9944030406246400.0000 - val_loss: 1090896728686592.0000 - val_mean_squared_error: 1090896862904320.0000\n",
      "Epoch 10/20\n",
      "47/47 [==============================] - 71s 1s/step - loss: 9944028258762752.0000 - mean_squared_error: 9944028258762752.0000 - val_loss: 1090896728686592.0000 - val_mean_squared_error: 1090896862904320.0000\n",
      "Epoch 11/20\n",
      "47/47 [==============================] - 71s 2s/step - loss: 9944029332504576.0000 - mean_squared_error: 9944029332504576.0000 - val_loss: 1090896728686592.0000 - val_mean_squared_error: 1090896862904320.0000\n",
      "Epoch 12/20\n",
      "47/47 [==============================] - 70s 1s/step - loss: 9944029332504576.0000 - mean_squared_error: 9944029332504576.0000 - val_loss: 1090896728686592.0000 - val_mean_squared_error: 1090896862904320.0000\n",
      "Epoch 13/20\n",
      "47/47 [==============================] - 66s 1s/step - loss: 9944029332504576.0000 - mean_squared_error: 9944029332504576.0000 - val_loss: 1090896728686592.0000 - val_mean_squared_error: 1090896862904320.0000\n",
      "Epoch 14/20\n",
      "47/47 [==============================] - 69s 1s/step - loss: 9944030406246400.0000 - mean_squared_error: 9944028258762752.0000 - val_loss: 1090896728686592.0000 - val_mean_squared_error: 1090896862904320.0000\n",
      "Epoch 15/20\n",
      "47/47 [==============================] - 65s 1s/step - loss: 9944029332504576.0000 - mean_squared_error: 9944029332504576.0000 - val_loss: 1090896728686592.0000 - val_mean_squared_error: 1090896862904320.0000\n",
      "Epoch 16/20\n",
      "47/47 [==============================] - 64s 1s/step - loss: 9944028258762752.0000 - mean_squared_error: 9944028258762752.0000 - val_loss: 1090896728686592.0000 - val_mean_squared_error: 1090896862904320.0000\n",
      "Epoch 17/20\n",
      "47/47 [==============================] - 63s 1s/step - loss: 9944029332504576.0000 - mean_squared_error: 9944030406246400.0000 - val_loss: 1090896728686592.0000 - val_mean_squared_error: 1090896862904320.0000\n",
      "Epoch 18/20\n",
      "47/47 [==============================] - 63s 1s/step - loss: 9944029332504576.0000 - mean_squared_error: 9944029332504576.0000 - val_loss: 1090896728686592.0000 - val_mean_squared_error: 1090896862904320.0000\n",
      "Epoch 19/20\n",
      "47/47 [==============================] - 64s 1s/step - loss: 9944028258762752.0000 - mean_squared_error: 9944029332504576.0000 - val_loss: 1090896728686592.0000 - val_mean_squared_error: 1090896862904320.0000\n",
      "Epoch 20/20\n",
      "47/47 [==============================] - 64s 1s/step - loss: 9944028258762752.0000 - mean_squared_error: 9944029332504576.0000 - val_loss: 1090896728686592.0000 - val_mean_squared_error: 1090896862904320.0000\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(maxLength,1))\n",
    "\n",
    "encoding_dim = 8\n",
    "no_of_layers = 1\n",
    "with_bottleneck = False\n",
    "\n",
    "prev_layer = input_layer\n",
    "\n",
    "for i in range(no_of_layers):\n",
    "        encoder = LSTM(int(encoding_dim / pow(2, i)),\n",
    "                        #activation=\"relu\",\n",
    "                       return_sequences=True,\n",
    "                       recurrent_dropout=0.1,\n",
    "                       dropout=0.1)(prev_layer)\n",
    "        prev_layer = encoder \n",
    "\n",
    "if with_bottleneck:\n",
    "        prev_layer = LSTM(int(encoding_dim / pow(2, no_of_layers + 1)),\n",
    "                         #activation=\"relu\",\n",
    "                          return_sequences=True,\n",
    "                          recurrent_dropout=0.1,\n",
    "                          dropout=0.1)(prev_layer)\n",
    "for j in range(no_of_layers - 1, -1, -1):\n",
    "        decoder = LSTM(int(encoding_dim / pow(2, j)),\n",
    "                        #activation='relu',\n",
    "                       return_sequences=True,\n",
    "                       recurrent_dropout=0.1,\n",
    "                       dropout=0.1)(prev_layer)\n",
    "        prev_layer = decoder\n",
    "prev_layer = TimeDistributed(Dense(1))(prev_layer)\n",
    "autoencoder = Model(inputs=input_layer, outputs=prev_layer)\n",
    "\n",
    "autoencoder.compile(optimizer='adam',\n",
    "                        loss='mean_squared_error',\n",
    "                        metrics=['mean_squared_error'])\n",
    "autoencoder.summary()   \n",
    "\n",
    "\n",
    "history = autoencoder.fit(X_train,\n",
    "                              X_train,\n",
    "                              epochs=20,\n",
    "                              batch_size=32,\n",
    "                              verbose=1,\n",
    "                              validation_split=0.2,\n",
    "                              shuffle=True).history\n",
    "\n",
    "autoencoder.save('encoder_lstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save('encoder_lstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = load_model('encoder_lstm.h5')\n",
    "#autoencoder = load_model('encoder_lstm_float.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from tensorflow.keras.layers import LSTM, GRU, Dense, Embedding, Dropout, GlobalAveragePooling1D, Flatten, SpatialDropout1D, Bidirectional\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 7s 114ms/step\n",
      "25/25 [==============================] - 3s 116ms/step\n"
     ]
    }
   ],
   "source": [
    "X_train_encode = autoencoder.predict(X_train)\n",
    "X_test_encode = autoencoder.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 513\n",
    "embedding_dim = 8\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "58/58 [==============================] - 35s 511ms/step - loss: 0.6321 - accuracy: 0.6724 - val_loss: 0.6199 - val_accuracy: 0.6809\n",
      "Epoch 2/15\n",
      "58/58 [==============================] - 26s 447ms/step - loss: 0.5940 - accuracy: 0.7139 - val_loss: 0.5965 - val_accuracy: 0.7010\n",
      "Epoch 3/15\n",
      "58/58 [==============================] - 27s 461ms/step - loss: 0.5636 - accuracy: 0.7355 - val_loss: 0.5889 - val_accuracy: 0.7098\n",
      "Epoch 4/15\n",
      "58/58 [==============================] - 26s 445ms/step - loss: 0.5653 - accuracy: 0.7328 - val_loss: 0.5900 - val_accuracy: 0.7060\n",
      "Epoch 5/15\n",
      "58/58 [==============================] - 27s 469ms/step - loss: 0.5912 - accuracy: 0.7134 - val_loss: 0.5940 - val_accuracy: 0.7085\n",
      "Epoch 6/15\n",
      "58/58 [==============================] - 26s 445ms/step - loss: 0.5613 - accuracy: 0.7398 - val_loss: 0.5945 - val_accuracy: 0.7085\n",
      "Epoch 7/15\n",
      "58/58 [==============================] - 26s 453ms/step - loss: 0.5594 - accuracy: 0.7392 - val_loss: 0.5991 - val_accuracy: 0.7073\n",
      "Epoch 8/15\n",
      "58/58 [==============================] - 26s 451ms/step - loss: 0.5626 - accuracy: 0.7398 - val_loss: 0.5950 - val_accuracy: 0.7098\n",
      "Epoch 9/15\n",
      "58/58 [==============================] - 26s 443ms/step - loss: 0.5566 - accuracy: 0.7387 - val_loss: 0.5867 - val_accuracy: 0.7161\n",
      "Epoch 10/15\n",
      "58/58 [==============================] - 27s 465ms/step - loss: 0.5540 - accuracy: 0.7419 - val_loss: 0.5892 - val_accuracy: 0.7111\n",
      "Epoch 11/15\n",
      "58/58 [==============================] - 25s 438ms/step - loss: 0.5550 - accuracy: 0.7446 - val_loss: 0.5953 - val_accuracy: 0.7073\n",
      "Epoch 12/15\n",
      "58/58 [==============================] - 26s 447ms/step - loss: 0.5480 - accuracy: 0.7500 - val_loss: 0.5940 - val_accuracy: 0.7123\n",
      "Epoch 13/15\n",
      "58/58 [==============================] - 26s 448ms/step - loss: 0.5485 - accuracy: 0.7495 - val_loss: 0.5975 - val_accuracy: 0.7048\n",
      "Epoch 14/15\n",
      "58/58 [==============================] - 27s 457ms/step - loss: 0.5519 - accuracy: 0.7435 - val_loss: 0.5890 - val_accuracy: 0.7060\n",
      "Epoch 15/15\n",
      "58/58 [==============================] - 26s 457ms/step - loss: 0.5555 - accuracy: 0.7441 - val_loss: 0.5896 - val_accuracy: 0.7073\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_26 (Bidirecti  (None, 128)              33792     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,921\n",
      "Trainable params: 33,921\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "#model2.add(Embedding(vocab_size,embedding_dim,input_length = maxLength))\n",
    "model2.add(Input(shape=(maxLength,1)))\n",
    "#model2.add(Embedding(vocab_size,embedding_dim,input_length = maxLength))\n",
    "model2.add(Bidirectional(LSTM(64,\n",
    "                              return_sequences = False)))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "model2.compile(loss = 'binary_crossentropy',\n",
    "               optimizer = 'adam',\n",
    "               metrics=['accuracy'])\n",
    "num_epochs = 30\n",
    "early_stop = EarlyStopping(monitor = 'val_loss',\n",
    "                           patience = 2)\n",
    "history = model2.fit(X_train_encode,\n",
    "                     y_train,\n",
    "                     epochs = num_epochs - 15,\n",
    "                     validation_data = (X_test_encode, y_test),\n",
    "                     #callbacks = [early_stop],\n",
    "                     verbose = 1)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 5s 185ms/step\n"
     ]
    }
   ],
   "source": [
    "yhat = model2.predict(X_test_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round(x, decimals=0):\n",
    "    b = 10**decimals\n",
    "    return torch.round(x*b)/b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.28670928]\n",
      " [0.28909412]\n",
      " [0.27974686]\n",
      " [0.27113873]\n",
      " [0.25898644]\n",
      " [0.27149856]\n",
      " [0.28905112]\n",
      " [0.56132954]\n",
      " [0.28138667]\n",
      " [0.29078704]\n",
      " [0.30036554]\n",
      " [0.28090277]\n",
      " [0.10616691]\n",
      " [0.25654718]\n",
      " [0.27844927]\n",
      " [0.26811486]\n",
      " [0.2578974 ]\n",
      " [0.27390265]\n",
      " [0.27195174]\n",
      " [0.29399776]\n",
      " [0.27066186]\n",
      " [0.25642967]\n",
      " [0.3191073 ]\n",
      " [0.26686493]\n",
      " [0.24465856]\n",
      " [0.9818195 ]\n",
      " [0.24725935]\n",
      " [0.26355925]\n",
      " [0.25541806]\n",
      " [0.35819772]\n",
      " [0.98808414]\n",
      " [0.3540238 ]\n",
      " [0.33295572]\n",
      " [0.2859252 ]\n",
      " [0.24963744]\n",
      " [0.26559332]\n",
      " [0.24733572]\n",
      " [0.24154803]\n",
      " [0.2692298 ]\n",
      " [0.2711611 ]\n",
      " [0.2845158 ]\n",
      " [0.78967303]\n",
      " [0.27890944]\n",
      " [0.26672766]\n",
      " [0.26289058]\n",
      " [0.30002376]\n",
      " [0.30156133]\n",
      " [0.2588529 ]\n",
      " [0.26344323]\n",
      " [0.98211896]\n",
      " [0.28085306]\n",
      " [0.27751133]\n",
      " [0.2652922 ]\n",
      " [0.26175797]\n",
      " [0.2899977 ]\n",
      " [0.26607534]\n",
      " [0.27067763]\n",
      " [0.2794828 ]\n",
      " [0.9921613 ]\n",
      " [0.28256145]\n",
      " [0.27506706]\n",
      " [0.25706133]\n",
      " [0.3539283 ]\n",
      " [0.28088543]\n",
      " [0.26046994]\n",
      " [0.9777208 ]\n",
      " [0.3019633 ]\n",
      " [0.27506495]\n",
      " [0.3336632 ]\n",
      " [0.26377672]\n",
      " [0.24795273]\n",
      " [0.26951048]\n",
      " [0.26955023]\n",
      " [0.28573364]\n",
      " [0.7610075 ]\n",
      " [0.27342686]\n",
      " [0.36429998]\n",
      " [0.28383425]\n",
      " [0.2602724 ]\n",
      " [0.28361306]\n",
      " [0.26091152]\n",
      " [0.26278463]\n",
      " [0.288019  ]\n",
      " [0.27127698]\n",
      " [0.2675828 ]\n",
      " [0.30776584]\n",
      " [0.27265063]\n",
      " [0.2712049 ]\n",
      " [0.25792766]\n",
      " [0.80452645]\n",
      " [0.2599991 ]\n",
      " [0.28082523]\n",
      " [0.34777206]\n",
      " [0.9860349 ]\n",
      " [0.27426746]\n",
      " [0.76094764]\n",
      " [0.2470002 ]\n",
      " [0.2804788 ]\n",
      " [0.24824823]\n",
      " [0.24281968]\n",
      " [0.30368876]\n",
      " [0.26962385]\n",
      " [0.3313574 ]\n",
      " [0.27011654]\n",
      " [0.27084866]\n",
      " [0.26470283]\n",
      " [0.2603559 ]\n",
      " [0.26445717]\n",
      " [0.28195685]\n",
      " [0.24838369]\n",
      " [0.8467797 ]\n",
      " [0.8969536 ]\n",
      " [0.27955377]\n",
      " [0.2765217 ]\n",
      " [0.2675828 ]\n",
      " [0.24288557]\n",
      " [0.24659023]\n",
      " [0.36398822]\n",
      " [0.2970278 ]\n",
      " [0.28348252]\n",
      " [0.26562944]\n",
      " [0.26502374]\n",
      " [0.33642563]\n",
      " [0.2637791 ]\n",
      " [0.26811635]\n",
      " [0.35316813]\n",
      " [0.25361732]\n",
      " [0.2616131 ]\n",
      " [0.28332266]\n",
      " [0.34236977]\n",
      " [0.266632  ]\n",
      " [0.28264982]\n",
      " [0.2546822 ]\n",
      " [0.25793004]\n",
      " [0.27121043]\n",
      " [0.25616512]\n",
      " [0.25902197]\n",
      " [0.26258293]\n",
      " [0.25610098]\n",
      " [0.29441708]\n",
      " [0.40135416]\n",
      " [0.26724726]\n",
      " [0.26175797]\n",
      " [0.30055398]\n",
      " [0.29034212]\n",
      " [0.28457764]\n",
      " [0.28201485]\n",
      " [0.27331528]\n",
      " [0.24915868]\n",
      " [0.2527397 ]\n",
      " [0.28581768]\n",
      " [0.27913293]\n",
      " [0.2943008 ]\n",
      " [0.25584993]\n",
      " [0.29280746]\n",
      " [0.26385388]\n",
      " [0.27529597]\n",
      " [0.3534047 ]\n",
      " [0.25916392]\n",
      " [0.359834  ]\n",
      " [0.2616425 ]\n",
      " [0.69519585]\n",
      " [0.27708125]\n",
      " [0.33593947]\n",
      " [0.24735044]\n",
      " [0.2745706 ]\n",
      " [0.26802185]\n",
      " [0.31749925]\n",
      " [0.26949796]\n",
      " [0.2603573 ]\n",
      " [0.28606495]\n",
      " [0.27970275]\n",
      " [0.9628751 ]\n",
      " [0.263982  ]\n",
      " [0.25460017]\n",
      " [0.27663797]\n",
      " [0.26225296]\n",
      " [0.33142558]\n",
      " [0.2709892 ]\n",
      " [0.26149943]\n",
      " [0.2701714 ]\n",
      " [0.2639574 ]\n",
      " [0.2499558 ]\n",
      " [0.27705777]\n",
      " [0.26524818]\n",
      " [0.3523251 ]\n",
      " [0.2582827 ]\n",
      " [0.2831432 ]\n",
      " [0.26372132]\n",
      " [0.2722976 ]\n",
      " [0.6951912 ]\n",
      " [0.27803397]\n",
      " [0.7882994 ]\n",
      " [0.27582204]\n",
      " [0.24963744]\n",
      " [0.25495782]\n",
      " [0.29157382]\n",
      " [0.28591898]\n",
      " [0.38050604]\n",
      " [0.28125918]\n",
      " [0.28808424]\n",
      " [0.33192638]\n",
      " [0.35533673]\n",
      " [0.27809668]\n",
      " [0.7621281 ]\n",
      " [0.9775377 ]\n",
      " [0.27943563]\n",
      " [0.2620307 ]\n",
      " [0.26858917]\n",
      " [0.29136246]\n",
      " [0.24853547]\n",
      " [0.25937507]\n",
      " [0.2970278 ]\n",
      " [0.27679428]\n",
      " [0.29883838]\n",
      " [0.26312733]\n",
      " [0.28202882]\n",
      " [0.26278463]\n",
      " [0.27812117]\n",
      " [0.28471392]\n",
      " [0.33367935]\n",
      " [0.28202337]\n",
      " [0.30848402]\n",
      " [0.9940731 ]\n",
      " [0.24978657]\n",
      " [0.28383425]\n",
      " [0.27647206]\n",
      " [0.28606495]\n",
      " [0.2787897 ]\n",
      " [0.27679428]\n",
      " [0.25407377]\n",
      " [0.2775541 ]\n",
      " [0.26222324]\n",
      " [0.33367935]\n",
      " [0.2554666 ]\n",
      " [0.28065977]\n",
      " [0.2707645 ]\n",
      " [0.269819  ]\n",
      " [0.25815552]\n",
      " [0.27935043]\n",
      " [0.29815453]\n",
      " [0.27301526]\n",
      " [0.25979027]\n",
      " [0.9919972 ]\n",
      " [0.26055932]\n",
      " [0.27172795]\n",
      " [0.2580224 ]\n",
      " [0.2602724 ]\n",
      " [0.2989075 ]\n",
      " [0.26371396]\n",
      " [0.9856193 ]\n",
      " [0.2865122 ]\n",
      " [0.26855385]\n",
      " [0.9912368 ]\n",
      " [0.23240116]\n",
      " [0.25556043]\n",
      " [0.26162308]\n",
      " [0.24771526]\n",
      " [0.2704175 ]\n",
      " [0.26059645]\n",
      " [0.25643185]\n",
      " [0.25337592]\n",
      " [0.7896746 ]\n",
      " [0.28150117]\n",
      " [0.26144725]\n",
      " [0.29942355]\n",
      " [0.29753274]\n",
      " [0.2774669 ]\n",
      " [0.29279456]\n",
      " [0.24682304]\n",
      " [0.2873295 ]\n",
      " [0.32186535]\n",
      " [0.27632257]\n",
      " [0.2870832 ]\n",
      " [0.27715525]\n",
      " [0.25191277]\n",
      " [0.27295288]\n",
      " [0.3405377 ]\n",
      " [0.26433963]\n",
      " [0.28571478]\n",
      " [0.25410733]\n",
      " [0.26147243]\n",
      " [0.26413718]\n",
      " [0.27729854]\n",
      " [0.28121272]\n",
      " [0.25558814]\n",
      " [0.2891552 ]\n",
      " [0.28502598]\n",
      " [0.28121272]\n",
      " [0.23948672]\n",
      " [0.26842734]\n",
      " [0.28045028]\n",
      " [0.27019837]\n",
      " [0.2963337 ]\n",
      " [0.99164283]\n",
      " [0.26117748]\n",
      " [0.2767038 ]\n",
      " [0.74134266]\n",
      " [0.24876101]\n",
      " [0.25643185]\n",
      " [0.28480732]\n",
      " [0.2732767 ]\n",
      " [0.26572472]\n",
      " [0.26697856]\n",
      " [0.36429998]\n",
      " [0.2754459 ]\n",
      " [0.17325091]\n",
      " [0.26366946]\n",
      " [0.25799918]\n",
      " [0.2978465 ]\n",
      " [0.3191073 ]\n",
      " [0.28503758]\n",
      " [0.26914296]\n",
      " [0.27696073]\n",
      " [0.99252135]\n",
      " [0.2652922 ]\n",
      " [0.26935613]\n",
      " [0.2561376 ]\n",
      " [0.29204136]\n",
      " [0.27439713]\n",
      " [0.26524052]\n",
      " [0.2615141 ]\n",
      " [0.2485034 ]\n",
      " [0.29357883]\n",
      " [0.99253523]\n",
      " [0.27904496]\n",
      " [0.26621792]\n",
      " [0.78336906]\n",
      " [0.25843444]\n",
      " [0.29084325]\n",
      " [0.2775074 ]\n",
      " [0.26692912]\n",
      " [0.2582827 ]\n",
      " [0.2505141 ]\n",
      " [0.3157833 ]\n",
      " [0.36613074]\n",
      " [0.2984913 ]\n",
      " [0.7606288 ]\n",
      " [0.2912997 ]\n",
      " [0.29122773]\n",
      " [0.28898552]\n",
      " [0.25655347]\n",
      " [0.25853735]\n",
      " [0.29580507]\n",
      " [0.27591735]\n",
      " [0.3012998 ]\n",
      " [0.25303516]\n",
      " [0.2812855 ]\n",
      " [0.2539654 ]\n",
      " [0.29719424]\n",
      " [0.7777971 ]\n",
      " [0.26821908]\n",
      " [0.26320755]\n",
      " [0.24237229]\n",
      " [0.34084046]\n",
      " [0.25239334]\n",
      " [0.27463463]\n",
      " [0.28405213]\n",
      " [0.26858917]\n",
      " [0.23660845]\n",
      " [0.26084182]\n",
      " [0.28278995]\n",
      " [0.30028167]\n",
      " [0.29192623]\n",
      " [0.27083364]\n",
      " [0.987882  ]\n",
      " [0.29209325]\n",
      " [0.99208236]\n",
      " [0.33593947]\n",
      " [0.30057952]\n",
      " [0.25544053]\n",
      " [0.22962745]\n",
      " [0.29783136]\n",
      " [0.26321647]\n",
      " [0.26838392]\n",
      " [0.26651016]\n",
      " [0.30194506]\n",
      " [0.24817428]\n",
      " [0.26031476]\n",
      " [0.25556794]\n",
      " [0.35045522]\n",
      " [0.24884124]\n",
      " [0.2615141 ]\n",
      " [0.28502598]\n",
      " [0.32822803]\n",
      " [0.3336632 ]\n",
      " [0.25537068]\n",
      " [0.28802586]\n",
      " [0.245056  ]\n",
      " [0.29037303]\n",
      " [0.95874643]\n",
      " [0.27349257]\n",
      " [0.25358102]\n",
      " [0.25377142]\n",
      " [0.26758182]\n",
      " [0.27942833]\n",
      " [0.99203104]\n",
      " [0.29088217]\n",
      " [0.2937898 ]\n",
      " [0.24856496]\n",
      " [0.28740612]\n",
      " [0.27732417]\n",
      " [0.28749093]\n",
      " [0.2871005 ]\n",
      " [0.29955387]\n",
      " [0.2863918 ]\n",
      " [0.2734425 ]\n",
      " [0.2863415 ]\n",
      " [0.26962385]\n",
      " [0.28511617]\n",
      " [0.99202394]\n",
      " [0.25793618]\n",
      " [0.28870425]\n",
      " [0.83754843]\n",
      " [0.26395747]\n",
      " [0.27421635]\n",
      " [0.2692849 ]\n",
      " [0.24673727]\n",
      " [0.35608527]\n",
      " [0.24450974]\n",
      " [0.2594669 ]\n",
      " [0.29591158]\n",
      " [0.34607112]\n",
      " [0.27407765]\n",
      " [0.2852903 ]\n",
      " [0.2794917 ]\n",
      " [0.24925858]\n",
      " [0.26444295]\n",
      " [0.26084787]\n",
      " [0.28277564]\n",
      " [0.27971452]\n",
      " [0.33711544]\n",
      " [0.28457764]\n",
      " [0.27051154]\n",
      " [0.27028129]\n",
      " [0.2761934 ]\n",
      " [0.99247134]\n",
      " [0.7868337 ]\n",
      " [0.27207577]\n",
      " [0.11116935]\n",
      " [0.26830348]\n",
      " [0.2376594 ]\n",
      " [0.29748577]\n",
      " [0.23660845]\n",
      " [0.25358996]\n",
      " [0.2688663 ]\n",
      " [0.11103498]\n",
      " [0.28784204]\n",
      " [0.24514848]\n",
      " [0.25185877]\n",
      " [0.28405213]\n",
      " [0.30195826]\n",
      " [0.34090143]\n",
      " [0.9924731 ]\n",
      " [0.26683727]\n",
      " [0.28384838]\n",
      " [0.28905123]\n",
      " [0.28652012]\n",
      " [0.2817889 ]\n",
      " [0.32186535]\n",
      " [0.27722004]\n",
      " [0.272539  ]\n",
      " [0.2871005 ]\n",
      " [0.26453903]\n",
      " [0.25687677]\n",
      " [0.27571592]\n",
      " [0.2710597 ]\n",
      " [0.9684383 ]\n",
      " [0.27084866]\n",
      " [0.2562931 ]\n",
      " [0.270234  ]\n",
      " [0.26949614]\n",
      " [0.26674467]\n",
      " [0.27180004]\n",
      " [0.32481506]\n",
      " [0.26376086]\n",
      " [0.26649567]\n",
      " [0.29318708]\n",
      " [0.22706053]\n",
      " [0.25811768]\n",
      " [0.2742728 ]\n",
      " [0.2943008 ]\n",
      " [0.26064572]\n",
      " [0.25867552]\n",
      " [0.29122773]\n",
      " [0.2808469 ]\n",
      " [0.28096807]\n",
      " [0.2621492 ]\n",
      " [0.26038486]\n",
      " [0.25793004]\n",
      " [0.47171324]\n",
      " [0.27400455]\n",
      " [0.27916473]\n",
      " [0.2580611 ]\n",
      " [0.27222535]\n",
      " [0.27980533]\n",
      " [0.25309375]\n",
      " [0.286725  ]\n",
      " [0.9884238 ]\n",
      " [0.2892743 ]\n",
      " [0.24844979]\n",
      " [0.29112852]\n",
      " [0.25359404]\n",
      " [0.2773089 ]\n",
      " [0.296081  ]\n",
      " [0.24860965]\n",
      " [0.2578974 ]\n",
      " [0.28116673]\n",
      " [0.25507557]\n",
      " [0.27060592]\n",
      " [0.7612563 ]\n",
      " [0.25778997]\n",
      " [0.28708997]\n",
      " [0.26930434]\n",
      " [0.2643168 ]\n",
      " [0.29512736]\n",
      " [0.41568047]\n",
      " [0.26360413]\n",
      " [0.25642967]\n",
      " [0.26988798]\n",
      " [0.2855533 ]\n",
      " [0.26222   ]\n",
      " [0.34364045]\n",
      " [0.9661111 ]\n",
      " [0.27173832]\n",
      " [0.24453843]\n",
      " [0.28827164]\n",
      " [0.24980137]\n",
      " [0.28249234]\n",
      " [0.28342465]\n",
      " [0.27618712]\n",
      " [0.2831432 ]\n",
      " [0.2819632 ]\n",
      " [0.29388985]\n",
      " [0.26105005]\n",
      " [0.78048015]\n",
      " [0.34826714]\n",
      " [0.26044062]\n",
      " [0.9921121 ]\n",
      " [0.26635864]\n",
      " [0.2627388 ]\n",
      " [0.2616726 ]\n",
      " [0.27758977]\n",
      " [0.2992071 ]\n",
      " [0.33502597]\n",
      " [0.2913374 ]\n",
      " [0.27257928]\n",
      " [0.25571206]\n",
      " [0.28214437]\n",
      " [0.28790587]\n",
      " [0.29279456]\n",
      " [0.25905672]\n",
      " [0.26365367]\n",
      " [0.26375455]\n",
      " [0.26031476]\n",
      " [0.2704175 ]\n",
      " [0.28030694]\n",
      " [0.26258293]\n",
      " [0.99321663]\n",
      " [0.26882592]\n",
      " [0.27648184]\n",
      " [0.4176579 ]\n",
      " [0.10829105]\n",
      " [0.28559473]\n",
      " [0.28226238]\n",
      " [0.27760568]\n",
      " [0.35305086]\n",
      " [0.35114864]\n",
      " [0.7629147 ]\n",
      " [0.27149856]\n",
      " [0.28390315]\n",
      " [0.2736474 ]\n",
      " [0.29027188]\n",
      " [0.2793039 ]\n",
      " [0.29266164]\n",
      " [0.33147597]\n",
      " [0.26941133]\n",
      " [0.27499476]\n",
      " [0.25816616]\n",
      " [0.2794828 ]\n",
      " [0.27726647]\n",
      " [0.33341742]\n",
      " [0.26951107]\n",
      " [0.9924638 ]\n",
      " [0.26707408]\n",
      " [0.7868604 ]\n",
      " [0.25147846]\n",
      " [0.29748577]\n",
      " [0.25541776]\n",
      " [0.2761934 ]\n",
      " [0.28480735]\n",
      " [0.2615616 ]\n",
      " [0.7608165 ]\n",
      " [0.3266962 ]\n",
      " [0.2677996 ]\n",
      " [0.7804678 ]\n",
      " [0.2859252 ]\n",
      " [0.256285  ]\n",
      " [0.9821186 ]\n",
      " [0.28103223]\n",
      " [0.2482434 ]\n",
      " [0.27467006]\n",
      " [0.7609462 ]\n",
      " [0.9924552 ]\n",
      " [0.7892951 ]\n",
      " [0.99423385]\n",
      " [0.27122143]\n",
      " [0.2764248 ]\n",
      " [0.27815995]\n",
      " [0.2618166 ]\n",
      " [0.27270362]\n",
      " [0.28797883]\n",
      " [0.2742432 ]\n",
      " [0.26622212]\n",
      " [0.24792968]\n",
      " [0.28442025]\n",
      " [0.2783333 ]\n",
      " [0.28073636]\n",
      " [0.8461425 ]\n",
      " [0.2728219 ]\n",
      " [0.7875441 ]\n",
      " [0.27678937]\n",
      " [0.2945771 ]\n",
      " [0.2904064 ]\n",
      " [0.2757516 ]\n",
      " [0.2805717 ]\n",
      " [0.38512266]\n",
      " [0.28884152]\n",
      " [0.29215717]\n",
      " [0.27089122]\n",
      " [0.29088217]\n",
      " [0.28201485]\n",
      " [0.9920883 ]\n",
      " [0.28190035]\n",
      " [0.27887774]\n",
      " [0.27178094]\n",
      " [0.3547763 ]\n",
      " [0.84614205]\n",
      " [0.26109028]\n",
      " [0.2561376 ]\n",
      " [0.29306078]\n",
      " [0.35912266]\n",
      " [0.25686806]\n",
      " [0.30169046]\n",
      " [0.27183884]\n",
      " [0.99224377]\n",
      " [0.2830434 ]\n",
      " [0.91722506]\n",
      " [0.2803999 ]\n",
      " [0.28652012]\n",
      " [0.24182367]\n",
      " [0.9878865 ]\n",
      " [0.26366723]\n",
      " [0.3547763 ]\n",
      " [0.27667913]\n",
      " [0.28439927]\n",
      " [0.2746705 ]\n",
      " [0.27942726]\n",
      " [0.29209325]\n",
      " [0.26497266]\n",
      " [0.25229692]\n",
      " [0.28849128]\n",
      " [0.28694275]\n",
      " [0.27751398]\n",
      " [0.29381612]\n",
      " [0.2611738 ]\n",
      " [0.2653411 ]\n",
      " [0.28537425]\n",
      " [0.27942833]\n",
      " [0.28629705]\n",
      " [0.23965655]\n",
      " [0.2551522 ]\n",
      " [0.29719424]\n",
      " [0.24888079]\n",
      " [0.34625968]\n",
      " [0.26674104]\n",
      " [0.30607814]\n",
      " [0.33516195]\n",
      " [0.7833684 ]\n",
      " [0.23979788]\n",
      " [0.25595668]\n",
      " [0.25759888]\n",
      " [0.26821908]\n",
      " [0.24801132]\n",
      " [0.7833691 ]\n",
      " [0.28442025]\n",
      " [0.26683727]\n",
      " [0.27962396]\n",
      " [0.26085356]\n",
      " [0.26125175]\n",
      " [0.34090143]\n",
      " [0.27716264]\n",
      " [0.25379643]\n",
      " [0.26147243]\n",
      " [0.258004  ]\n",
      " [0.2526828 ]\n",
      " [0.22722395]\n",
      " [0.29732862]\n",
      " [0.24904898]\n",
      " [0.33457774]\n",
      " [0.9103004 ]\n",
      " [0.27986205]\n",
      " [0.2849119 ]\n",
      " [0.2629879 ]\n",
      " [0.3490077 ]\n",
      " [0.28511617]\n",
      " [0.2689293 ]\n",
      " [0.27217174]\n",
      " [0.33144197]\n",
      " [0.2505313 ]\n",
      " [0.26672408]\n",
      " [0.2770007 ]\n",
      " [0.26216862]\n",
      " [0.24288557]\n",
      " [0.26207548]\n",
      " [0.27449405]\n",
      " [0.26715228]\n",
      " [0.28915516]\n",
      " [0.28459057]\n",
      " [0.28806034]\n",
      " [0.28623965]\n",
      " [0.2881121 ]\n",
      " [0.25386986]\n",
      " [0.25358996]\n",
      " [0.2665342 ]\n",
      " [0.11758912]\n",
      " [0.9767855 ]\n",
      " [0.26951048]\n",
      " [0.78336465]\n",
      " [0.28708774]\n",
      " [0.27957922]\n",
      " [0.25003222]\n",
      " [0.35476252]\n",
      " [0.26387095]\n",
      " [0.27247658]\n",
      " [0.25986522]\n",
      " [0.9775423 ]\n",
      " [0.30368876]\n",
      " [0.24725935]\n",
      " [0.7109446 ]\n",
      " [0.25239828]\n",
      " [0.2910427 ]\n",
      " [0.3598884 ]\n",
      " [0.33144838]\n",
      " [0.2944265 ]\n",
      " [0.2815854 ]\n",
      " [0.2790434 ]\n",
      " [0.7868327 ]\n",
      " [0.994219  ]\n",
      " [0.2767038 ]\n",
      " [0.2550626 ]\n",
      " [0.27178094]\n",
      " [0.28803363]\n",
      " [0.30607814]\n",
      " [0.25307506]\n",
      " [0.2537677 ]\n",
      " [0.26674467]\n",
      " [0.2698506 ]\n",
      " [0.11494745]\n",
      " [0.35686538]\n",
      " [0.7868362 ]\n",
      " [0.28165296]\n",
      " [0.27915266]\n",
      " [0.9921591 ]\n",
      " [0.10128938]\n",
      " [0.27508134]\n",
      " [0.2758336 ]\n",
      " [0.26406622]\n",
      " [0.25377506]\n",
      " [0.27816716]\n",
      " [0.28749093]\n",
      " [0.2703563 ]\n",
      " [0.26954514]\n",
      " [0.17217045]\n",
      " [0.2895832 ]\n",
      " [0.29066107]\n",
      " [0.27735937]\n",
      " [0.28610465]\n",
      " [0.28165296]\n",
      " [0.27913293]\n",
      " [0.2726407 ]\n",
      " [0.2803999 ]\n",
      " [0.78338134]\n",
      " [0.2657177 ]\n",
      " [0.74083614]\n",
      " [0.25584993]\n",
      " [0.25792766]\n",
      " [0.27426746]\n",
      " [0.27735937]\n",
      " [0.2789229 ]\n",
      " [0.2817889 ]\n",
      " [0.2635737 ]\n",
      " [0.28183112]\n",
      " [0.98314893]\n",
      " [0.34015474]\n",
      " [0.28328535]]\n",
      "Counter({0: 701, 1: 95})\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.97      0.80       497\n",
      "           1       0.82      0.26      0.40       299\n",
      "\n",
      "    accuracy                           0.70       796\n",
      "   macro avg       0.75      0.61      0.60       796\n",
      "weighted avg       0.74      0.70      0.65       796\n",
      "\n",
      "0.39593908629441626\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#scores = model2.evaluate(X_test, y_test, verbose=1)\n",
    "print(yhat)\n",
    "#print(y_test[1])\n",
    "y_pred_bool = pd.cut(x=yhat.flatten(),bins=[0,0.355,1],labels=[0,1])\n",
    "#y_pred_bool =  torch.round(torch.tensor(yhat))\n",
    "#y_pred_bool = y_pred_bool.numpy()\n",
    "print(collections.Counter(y_pred_bool.tolist()))\n",
    "plt.scatter(y_test,yhat)\n",
    "plt.show()\n",
    "#print(pd.DataFrame(y_pred_bool).describe())\n",
    "#print(\"Accuracy: %.2f%%\" % (scores[1]*100)) \n",
    "print(classification_report(y_test, y_pred_bool))\n",
    "acc = accuracy_score( y_pred_bool,y_test)\n",
    "# print(acc)\n",
    "print(f1_score(y_test, y_pred_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "sns.set(font_scale = 1.5)\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    confusion_matrix(y_test, y_pred_bool), # confusion matrix 2D array \n",
    "    annot=True, # show numbers in the cells\n",
    "    fmt='d', # show numbers as integers\n",
    "    cbar=False, # don't show the color bar\n",
    "    cmap='flag', # customize color map\n",
    "    vmax=175 # to get better color contrast\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Predicted\", labelpad=20)\n",
    "ax.set_ylabel(\"Actual\", labelpad=20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.29, 0.02, 0.04]\n",
      "[0.36, 0.9, 0.51]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[221], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plot_classification_report(classification_report(y_test, y_pred_bool))\n",
      "Cell \u001b[1;32mIn[220], line 11\u001b[0m, in \u001b[0;36mplot_classification_report\u001b[1;34m(cr, title, with_avg_total, cmap)\u001b[0m\n\u001b[0;32m      9\u001b[0m t \u001b[39m=\u001b[39m line\u001b[39m.\u001b[39msplit()\n\u001b[0;32m     10\u001b[0m \u001b[39m# print(t)\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m classes\u001b[39m.\u001b[39mappend(t[\u001b[39m0\u001b[39;49m])\n\u001b[0;32m     12\u001b[0m v \u001b[39m=\u001b[39m [\u001b[39mfloat\u001b[39m(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m t[\u001b[39m1\u001b[39m: \u001b[39mlen\u001b[39m(t) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m]]\n\u001b[0;32m     13\u001b[0m \u001b[39mprint\u001b[39m(v)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bfc6e335c128585d36af7a059510d5d913fec349af665acf4002268031b2667f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
